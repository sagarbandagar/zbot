# ğŸ¤– ZBot - AI Chatbot with Kubernetes

A full-stack AI chatbot application with FastAPI backend, HTML/JS frontend, and Kubernetes deployment.

**Latest Update**: Testing CI/CD pipeline with secrets configured! ğŸš€âœ…

## ğŸ—ï¸ Architecture

```
Frontend (HTML/JS) â†’ nginx â†’ WebSocket â†’ Backend (FastAPI) â†’ OpenAI API
```

## ğŸš€ Features

- Real-time chat with WebSocket
- OpenAI GPT integration
- Docker containerization
- Kubernetes deployment
- Automated CI/CD with GitHub Actions
- Internet access via ngrok

## ğŸ“ Project Structure

```
zbot/
â”œâ”€â”€ front-end/              # HTML/CSS/JS frontend
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ script.js
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ nginx.conf
â”œâ”€â”€ back-end/               # Python FastAPI backend
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirement.txt
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ ws_handler.py
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ openai_services.py
â”œâ”€â”€ k8s/                    # Kubernetes manifests
â”‚   â”œâ”€â”€ secrets.yaml
â”‚   â”œâ”€â”€ backend-deployment.yaml
â”‚   â”œâ”€â”€ backend-service.yaml
â”‚   â”œâ”€â”€ frontend-deployment.yaml
â”‚   â””â”€â”€ frontend-service.yaml
â””â”€â”€ .github/workflows/      # CI/CD pipeline
    â””â”€â”€ ci-cd.yml
```

## ğŸ”§ Local Development

### Prerequisites
- Python 3.9+
- Docker
- Kubernetes (minikube)
- OpenAI API key

### Setup
1. Clone repository
2. Set OpenAI API key in `.env`
3. Build Docker images
4. Deploy to Kubernetes

## ğŸŒ Deployment

The application automatically deploys on push to main branch via GitHub Actions.

### Manual Deployment
```bash
# Build and push images
docker build -t sagarbandagar/zbot:frontend ./front-end
docker build -t sagarbandagar/zbot:backend ./back-end
docker push sagarbandagar/zbot:frontend
docker push sagarbandagar/zbot:backend

# Deploy to Kubernetes
kubectl apply -f k8s/
```

## ğŸ”„ CI/CD

Automated deployment pipeline:
1. Build Docker images
2. Push to Docker Hub
3. Deploy to Kubernetes
4. Verify deployment

## ğŸ“ Environment Variables

- `OPENAI_API_KEY`: Your OpenAI API key
- `OPENAI_MODEL`: GPT model (default: gpt-3.5-turbo)

## ğŸš€ Live Demo

Access the live application via ngrok URL (provided in deployment logs).

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

## ğŸ“„ License

MIT License